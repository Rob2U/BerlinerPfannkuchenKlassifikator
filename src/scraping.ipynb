{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_to_end(wd: webdriver):\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(wd: webdriver.Chrome, element_count: int, element_class: str, url: str):\n",
    "    wd.get(url=url)\n",
    "    \n",
    "    img_urls = set()\n",
    "    img_limit_reached = False\n",
    "    \n",
    "    while len(img_urls) < element_count or img_limit_reached:\n",
    "        img_limit_reached = True\n",
    "        scroll_to_end(wd=wd)\n",
    "        \n",
    "        results = wd.find_elements_by_class_name(element_class)\n",
    "        res_count = len(results)\n",
    "        \n",
    "        for elem in results:\n",
    "            if len(img_urls) >= element_count:\n",
    "                break\n",
    "            if elem.get_attribute('src') and 'http' in elem.get_attribute('src') and elem.get_attribute('src') not in img_urls:\n",
    "                    img_urls.add(elem.get_attribute('src'))\n",
    "                    img_limit_reached = False\n",
    "    wd.quit()\n",
    "    return img_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img: Image, img_size: int):\n",
    "    default_img = Image.new('RGB', (img_size, img_size), (0, 0, 0))\n",
    "    \n",
    "    img_ratio = img.width / img.height\n",
    "    if img_ratio > 1:\n",
    "        img = img.resize((img_size , int(img_size / img_ratio)))\n",
    "    else:\n",
    "        img = img.resize((int(img_size * img_ratio), img_size))\n",
    "    \n",
    "    img_pos_center = (img_size - img.width) // 2 , (img_size - img.height) // 2\n",
    "    default_img.paste(img, img_pos_center)\n",
    "    default_img = default_img.convert('RGB')\n",
    "    \n",
    "    return default_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img(path:str, url:str):\n",
    "    try:\n",
    "        img = requests.get(url).content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error while trying to download: {0} \\n\".format(url))\n",
    "\n",
    "    try:\n",
    "        img_data = io.BytesIO(img)\n",
    "        \n",
    "        image = Image.open(img_data).convert('RGB')\n",
    "        image = preprocess_image(image, 112) # 224 is the size of the input layer of the model\n",
    "        file_path = os.path.join(path, hashlib.sha1(img).hexdigest() + '.bmp')\n",
    "        with open(file_path, 'wb') as f:\n",
    "            image.save(f,\"BMP\")\n",
    "    except Exception as e:\n",
    "        print(\"Error {1} while trying to store: {0}\".format(url, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_images(path: str, url: str, count: int):\n",
    "    driver = webdriver.Chrome('/Users/robert/Documents/RepositorysLocal/BerlinerPfannkuchenKlassifikatior/chromedriver_mac_arm64/chromedriver')\n",
    "    img_urls = get_images(wd=driver, element_count=count, element_class=\"rg_i.Q4LuWd\", url=url) #rg_i.Q4LuWd is the class of the images in the google search\n",
    "    \n",
    "    for img_url in img_urls:\n",
    "        save_img(path, img_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/robert/Documents/RepositorysLocal/BerlinerPfannkuchenKlassifikatior/BerlinerPfannkuchenKlassifikator/data\"\n",
    "url_berliner = \"https://www.google.com/search?q=Berliner+(Geb%C3%A4ck)&tbm=isch&ved=2ahUKEwikusWEnOP8AhWcxrsIHa14AdYQ2-cCegQIABAA&oq=Berliner+(Geb%C3%A4ck)&gs_lcp=CgNpbWcQAzIECAAQHjIECAAQHjIECAAQHjoFCAAQgAQ6BggAEAgQHlDyAliYH2DrIWgAcAB4AIABgwGIAbMFkgEEMTAuMZgBAKABAaoBC2d3cy13aXotaW1nwAEB&sclient=img&ei=PmPRY6SjApyN7_UPrfGFsA0&bih=957&biw=1200\"\n",
    "url_pfannkuchen = \"https://www.google.com/search?q=eierkuchen&tbm=isch&ved=2ahUKEwj7pPPKteP8AhVQgqQKHelbCqcQ2-cCegQIABAA&oq=eierkuchen&gs_lcp=CgNpbWcQAzIHCAAQsQMQQzIFCAAQgAQyBAgAEEMyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEMgUIABCABDIFCAAQgAQyBQgAEIAEOggIABCABBCxAzoJCAAQgAQQChAYUPwGWJQcYKIeaAJwAHgAgAFOiAGoBpIBAjEzmAEAoAEBqgELZ3dzLXdpei1pbWfAAQE&sclient=img&ei=CH7RY_uAHdCEkgXpt6m4Cg&bih=1045&biw=1679\"\n",
    "url_krapfen = \"https://www.google.com/search?q=krapfen&client=safari&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjzyL6mgOT8AhW6QPEDHcq7Ac0Q_AUoAXoECAEQAw&biw=1800&bih=1046&dpr=2\"\n",
    "\n",
    "scrape_images(path + \"/berliner\", url_berliner, 400)\n",
    "scrape_images(path + \"/pfannkuchen\", url_pfannkuchen, 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_krapfen = \"https://www.google.com/search?q=krapfen&client=safari&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjzyL6mgOT8AhW6QPEDHcq7Ac0Q_AUoAXoECAEQAw&biw=1800&bih=1046&dpr=2\"\n",
    "scrape_images(\"/Users/robert/Documents/RepositorysLocal/BerlinerPfannkuchenKlassifikatior/BerlinerPfannkuchenKlassifikator\", url_krapfen, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6da7fd945713e64da6cbf98a618bc2c3ff6cb6697c7e79e8c184f718774efc42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
